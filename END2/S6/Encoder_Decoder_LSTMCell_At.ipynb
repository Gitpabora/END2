{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Encoder_Decoder_LSTMCell_At.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzlmnUwmDW-_"
      },
      "source": [
        "### Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltd8uj8o5-qw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "\n",
        "import os, pickle\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEOZp27rDeEm"
      },
      "source": [
        "### Upload the tweet csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4eAjHGbFON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1f5abf4f-fa7f-4097-e29b-467ca1e0cc52"
      },
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv( \"/content/tweets.csv\")  \n",
        "df.tail()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>@liberalminds Its trending idiot.. Did you loo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1360</th>\n",
              "      <td>RT @AstoldByBass: #KimKardashiansNextBoyfriend...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>RT @GatorNation41: gas was $1.92 when Obama to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1362</th>\n",
              "      <td>@xShwag haha i know im just so smart, i mean y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1363</th>\n",
              "      <td>#OBAMA:  DICTATOR IN TRAINING.  If he passes t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweets  labels\n",
              "1359  @liberalminds Its trending idiot.. Did you loo...       0\n",
              "1360  RT @AstoldByBass: #KimKardashiansNextBoyfriend...       0\n",
              "1361  RT @GatorNation41: gas was $1.92 when Obama to...       1\n",
              "1362  @xShwag haha i know im just so smart, i mean y...       1\n",
              "1363  #OBAMA:  DICTATOR IN TRAINING.  If he passes t...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE-ylf6C6BJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593f48ab-5770-49e0-c0c2-54d6d57897c5"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkxhrQox6Ju3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6196bf9d-6ce6-4fcc-d40f-eeefafa04da4"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbqEGu8FDw4R"
      },
      "source": [
        "### Set a seed value to enable repeatibility of model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kqZx2hG6e4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c286ea-d852-4a44-f721-c60fafc4a159"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9914441a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQki6r1xEHn2"
      },
      "source": [
        "### Create Field and LabelField variables to hold the comment and label information\n",
        "\n",
        "**Field** - Defines a datatype together with instructions for converting to Tensor.\n",
        "\n",
        "Field class models common text processing datatypes that can be represented by tensors. It holds a Vocab object that defines the set of possible values for elements of the field and their corresponding numerical representations. The Field object also holds other parameters relating to how a datatype should be numericalized, such as a tokenization method and the kind of Tensor that should be produced.\n",
        "\n",
        "1.   The tweet will be stored in **Tweet** Field object\n",
        "2.   The label will be stored in **Label** LabelField object\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3eiDVx6mKf"
      },
      "source": [
        "Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mah6J3vsESsx"
      },
      "source": [
        "#### Map the 2 variables to column header \n",
        "\n",
        "| Column header | Variable name |\n",
        "| --- | --- |\n",
        "| **tweet** | Tweet |\n",
        "| **label** | Label |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-by1zHIV7LPI"
      },
      "source": [
        "fields = [('tweet', Tweet), ('label', Label)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK04HuwREqPW"
      },
      "source": [
        "### Create a list of example\n",
        "\n",
        "by doing list comprehension of the tweet and label dataframe generated from the csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxmCFTgk797i"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc9xHciZEyJu"
      },
      "source": [
        "### Create the Dataset \n",
        "\n",
        "by providing the above list of examples and the field mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lj9XCy38OqE"
      },
      "source": [
        "twitterDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rptONIZGBmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9d9e1e-c467-4548-be5f-9767a7b41fe6"
      },
      "source": [
        "twitterDataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.legacy.data.dataset.Dataset at 0x7f98bb197f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9ueqdslE3Me"
      },
      "source": [
        "### Split the dataset into\n",
        "\n",
        "train and validation in the ratio of **85:15**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIA3n0l8m2x"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[85, 15], random_state = random.seed(SEED))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91fhtSKS8y3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4347218-8ff8-4c60-ce43-3d0a9a779c1e"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wllgrWlVGhBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e972c37-2e9a-4c0a-e55c-c7c9cbbd957c"
      },
      "source": [
        "train.fields"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': <torchtext.legacy.data.field.LabelField at 0x7f98bc735b10>,\n",
              " 'tweet': <torchtext.legacy.data.field.Field at 0x7f99130ebad0>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09AOF296E--e"
      },
      "source": [
        "### a training example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCDhbBKJ81ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea6d3df-6d30-40da-fb72-88306104a55c"
      },
      "source": [
        "vars(train.examples[15])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'tweet': ['In',\n",
              "  'his',\n",
              "  'teen',\n",
              "  'years',\n",
              "  ',',\n",
              "  'Obama',\n",
              "  'has',\n",
              "  'been',\n",
              "  'known',\n",
              "  'to',\n",
              "  'use',\n",
              "  'marijuana',\n",
              "  'and',\n",
              "  'cocaine',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPrsDbp8FEIW"
      },
      "source": [
        "A Vocab object defines the set of possible values for elements of the field and their corresponding numerical representations.\n",
        "\n",
        "Create Vocab object of the tweets and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_K23gxx84-K"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCPG8VrE9MKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc13242-89d0-46d7-afef-5cb98d43ad78"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBmMQQcX9SZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549746eb-f061-46e2-b9c8-8c0b7c8fc1b6"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYkMaqCOFWCG"
      },
      "source": [
        "### Use the BucketIterator to split and create \n",
        "\n",
        "1.   train iterator\n",
        "2.   validation iterator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJyulXA9sEr"
      },
      "source": [
        "batch_size = 32\n",
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = batch_size, \n",
        "                                                            sort_key = lambda x: len(x.tweet),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mfSHuiZFd63"
      },
      "source": [
        "### Save the Vocab object for later use during testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NVSpoV-Uaj"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT56G_9RFk8m"
      },
      "source": [
        "### Model class for training and validation\n",
        "\n",
        "The model has\n",
        "\n",
        "1.   An embedding layer which stores the list of words seen in the dataset and has weights attached to each word.These weights are adjusted during backpropagation to enable the model to converge at global minimum.\n",
        "\n",
        "2.   The model processes words in a sentence to encode the information ,\n",
        "\n",
        ">>   the sentences in the batch are padded with 0 to match the longest sentence in the batch.Here **nn.utils.rnn.pad_sequence** is used to pad the batch of sentences.\n",
        "\n",
        ">>   hidden state and cell state are initialized to 0 , before calling the encoder.\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "> *Step 1:* The word of the sentence is processed in left to right order. Each word is fed to a LSTMCell method , the hidden state returned is passed along with the next word.The hidden state is also stored in an array in the same order i.e from left to right.\n",
        "\n",
        "**Decoder**\n",
        "\n",
        "> *Step 2:* The hidden state from step 1 are vertically stacked and then reshaped to - sequence length x batch size x  embedded dimension.\n",
        "\n",
        ">> *Attention mechanism:* An attention mechanism is baked into the decoder\n",
        "\n",
        ">>> The last hidden state of the decoder is paired with each hidden state of the encoder.\n",
        "\n",
        ">>> Each pair is passed to a linear layer  to get the weight for that word\n",
        "\n",
        ">>> All the weights are then stacked vertically and reshaped to get the relative weight of each word w.r.t the sentence using a softmax function.\n",
        "\n",
        ">>> The relative weight vector is multiplied with the singlevector generated by the encoder to get the **Context vector** of the word w.r.t the sentence.\n",
        "\n",
        "> The context vector of the word and the last hidden state of the decoder is fed to  LSTMCell in a loop.\n",
        "\n",
        "3.   Output of the decoder is fed to a linear layer to return 3 class values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTxS2HF4dJu4"
      },
      "source": [
        "### A global flag is used to check whether to print the encoder and decoder output at each step\n",
        "\n",
        "*   printEncoderDecoderOutput \n",
        "\n",
        "This flag is false during training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQnNcH6-oZZ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "printEncoderDecoderOutput = False\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()  \n",
        "        ## store the hidden state   \n",
        "        self.hidden_dim = hidden_dim     \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        \n",
        "        # LSTMCell layer for processing words from left to right\n",
        "        self.encoder_fwd = nn.LSTMCell(hidden_dim, \n",
        "                           hidden_dim)\n",
        "\n",
        "        # LSTMCell layer to process the hidden state returned by the encoder.\n",
        "        self.decoder = nn.LSTMCell(hidden_dim, \n",
        "                           hidden_dim)\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.attentionfc = nn.Linear(hidden_dim*2, 1)\n",
        "\n",
        "    def attention(self, decoderhidden, singlevector,batchsize, seqlen):\n",
        "\n",
        "        #print('atn sv',singlevector.size())\n",
        "        attention = []\n",
        "        for i in range(seqlen):\n",
        "\n",
        "          attentionhidden = torch.cat((decoderhidden,singlevector[i]),1)\n",
        "          #attentionhidden = attentionhidden.to(device)\n",
        "          #print(attentionhidden.size())\n",
        "          attentionout = self.attentionfc(attentionhidden)\n",
        "          attention.append(attentionout)\n",
        "          \n",
        "        tup_attention = tuple(a for a in attention)\n",
        "        attentionvstack = torch.vstack(tup_attention)\n",
        "        attentionvector = attentionvstack.reshape(batchsize, seqlen)\n",
        "        attentionvector = attentionvector.unsqueeze(1)\n",
        "\n",
        "        alpha = F.softmax(attentionvector , dim=1)\n",
        "        \n",
        "        reshapedsinglevector = singlevector.reshape(batchsize, seqlen , self.hidden_dim)\n",
        "        #print('alp',alpha.size() , reshapedsinglevector.size())\n",
        "        \n",
        "        context = torch.bmm(alpha,reshapedsinglevector)\n",
        "\n",
        "        context = context.squeeze(1)\n",
        "\n",
        "        return context\n",
        "          \n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        global printEncoderDecoderOutput\n",
        "\n",
        "        # Initialization of hidden state and cell state for LSTMCell\n",
        "        hidden_fwd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "        cell_fwd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "\n",
        "        # Weights initialization\n",
        "        torch.nn.init.xavier_normal_(hidden_fwd)\n",
        "        torch.nn.init.xavier_normal_(cell_fwd)\n",
        "        #print(text_lengths)\n",
        "\n",
        "        hidden_fwd , cell_fwd = hidden_fwd.to(device) , cell_fwd.to(device) \n",
        "        \n",
        "\n",
        "        # Initialization of hidden state and cell state for decoder LSTMCell\n",
        "        hidden_dcd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "        cell_dcd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "\n",
        "        # Weights initialization\n",
        "        torch.nn.init.xavier_normal_(hidden_dcd)\n",
        "        torch.nn.init.xavier_normal_(cell_dcd)\n",
        "        #print(text_lengths)\n",
        "\n",
        "        hidden_dcd , cell_dcd = hidden_dcd.to(device) , cell_dcd.to(device) \n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "\n",
        "        # padding the batch\n",
        "        packed_embedded = nn.utils.rnn.pad_sequence(embedded, batch_first=True)\n",
        "\n",
        "        # shuffle the packed embedded tensor to bring the 2nd dim to 1st dim , this dim holds the padded string string length.\n",
        "        # We will iterate through this tensor to fetch the words from left to right.\n",
        "        packed_embedded = packed_embedded.view(packed_embedded.data.size(1), text.size(0), -1)\n",
        "        \n",
        "        bsize = packed_embedded.data.size()[1]\n",
        "        seq_len = packed_embedded.data.size(0)\n",
        "\n",
        "        ## Encoder block\n",
        "        hiddenFwdList = []\n",
        "        for i in range(packed_embedded.data.size(0)):  \n",
        "          \n",
        "          hidden_fwd, cell_fwd = self.encoder_fwd(packed_embedded[i] , (hidden_fwd, cell_fwd))\n",
        "          # save the hidden state in a list for use during decode\n",
        "          hiddenFwdList.append(hidden_fwd)\n",
        "          \n",
        "          if printEncoderDecoderOutput:\n",
        "            print('encdr word ', i ,hidden_fwd.size(),hidden_fwd)\n",
        "\n",
        "\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # create a tuple of all the hidden state from left to right\n",
        "        tup_hidden = tuple(h for h in hiddenFwdList)\n",
        "\n",
        "        # vertically stack the hidden state \n",
        "        vstack_hidden = torch.vstack(tup_hidden)\n",
        "        \n",
        "        # reshape the vertically stacked tensor to shape - batch size x seq_len x hidden dimension\n",
        "        singlehiddenvector = vstack_hidden.reshape( seq_len , bsize , -1 )\n",
        "\n",
        "        ## decode block\n",
        "        # loop through each hidden state of the encoder along with previous hidden state of decoder\n",
        "        #print('pkd ',packed_embedded[1].size())\n",
        "        for i in range(packed_embedded.data.size(0)):  \n",
        "          contextvector = self.attention(hidden_dcd, singlehiddenvector, bsize, seq_len)\n",
        "          #print(contextvector)\n",
        "          hidden_dcd, cell_dcd = self.decoder(contextvector , (hidden_dcd, cell_dcd))\n",
        "          \n",
        "          if printEncoderDecoderOutput:\n",
        "            print('decd word ', i ,hidden_dcd.size(),hidden_dcd)\n",
        "          \n",
        "        \n",
        "        dense_outputs = self.fc(hidden_dcd)\n",
        "        #print(dense_outputs)\n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs, dim=1)\n",
        "        #print(output)\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1YPR0X0VoG9"
      },
      "source": [
        "### Set the hyperparameters before running the model\n",
        "\n",
        "1.   dropout\n",
        "2.   number of nodes in embedding layer\n",
        "3.   number of nodes in hidden layer\n",
        "4.   number of layers in LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNWimMMAKya"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRextCcAASGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50eaa9d3-9b9b-4ec0-e41f-52ea91a1ab5d"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4651, 100)\n",
            "  (encoder_fwd): LSTMCell(100, 100)\n",
            "  (decoder): LSTMCell(100, 100)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            "  (attentionfc): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n",
            "The model has 627,204 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3rz1d_VV6Dh"
      },
      "source": [
        "### A utility function to calculate the model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPK6b19HATLm"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "learning_rate = 2e-1\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sth9nOW6WIrh"
      },
      "source": [
        "### wrapper function to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8t9iWwqAify"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweet \n",
        "        tweet, tweet_lengths = tweet.to(device), tweet_lengths.to(device) \n",
        "        #print(tweet_lengths)\n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        #print(predictions.shape, len(batch.label))\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ektXSpEmWKai"
      },
      "source": [
        "### wrapper function to evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBXHd5JAuX-"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweet\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            if (len(predictions.size())<2):\n",
        "              predictions = predictions.unsqueeze(0)\n",
        "\n",
        "            #print(tweet_lengths , predictions.size(), batch.label.size())\n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSaQQNe5WT1x"
      },
      "source": [
        "### Run the model over few epochs to see the model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7UPwN0KAvVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec72cfb-e6bc-453f-c8ee-d5b00bc5ff71"
      },
      "source": [
        "\n",
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "trainLossList = []\n",
        "valLossList = []\n",
        "\n",
        "trainAccyList = []\n",
        "valAccyList = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    trainLossList.append(round(train_loss,2))\n",
        "    valLossList.append(round(valid_loss,2))\n",
        "\n",
        "    trainAccyList.append(round(train_acc,2))\n",
        "    valAccyList.append(round(valid_acc,2))\n",
        "\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.873 | Train Acc: 66.93%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kaT0i4UWfIK"
      },
      "source": [
        "### A graph of model performance \n",
        "\n",
        "1.   Training and validation accuracy across different epochs\n",
        "2.   Training and validation loss across different epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl132D123vmo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "573087ca-1536-4e5a-f5d7-9402dea6c87c"
      },
      "source": [
        "xpoints = np.arange(len(trainLossList))\n",
        "ypoints4 = trainAccyList\n",
        "ypoints6 = valAccyList\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 8]\n",
        "plt.plot(xpoints, ypoints4, label = \"$ Training Accuracy $\" )\n",
        "plt.plot(xpoints, ypoints6, label = \"$ Validation Accuracy $\" )\n",
        "\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "plt.title(\"model performance\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy \")\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk9H1Sxn3vjx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "dc736a8f-0e15-46eb-ca27-a5bae7e02eab"
      },
      "source": [
        "xpoints = np.arange(len(trainLossList))\n",
        "ypoints0 = trainLossList\n",
        "ypoints2 = valLossList\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10,8]\n",
        "plt.plot(xpoints, ypoints0 , label = \"$ Training Loss $\" )\n",
        "plt.plot(xpoints, ypoints2, label = \"$ Validation Loss $\" )\n",
        "\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "plt.title(\"model performance\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss \")\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ9kTRpeWwoy"
      },
      "source": [
        "### A utility function to classify any tweets\n",
        "\n",
        "1.   saved weights are used to classify any input string to predict a label\n",
        "2.   a cached tokenizer which was saved earlier is used\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCGxks4AxT3"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    \n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    #print(tokenized)\n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized] \n",
        "    #print(indexed)       \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    #print(tensor)\n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    #print(tensor)\n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    #print(length_tensor)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    #print(pred.size(),pred)\n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgwS0wUCdtOi"
      },
      "source": [
        "### Classify a single sentence and print the hidden state at each step of encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1mmb9YiHWOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "efda1cfc-8e28-42ce-985a-c011f3c03c9e"
      },
      "source": [
        "printEncoderDecoderOutput = True\n",
        "classify_tweet(\"An invalid explanation for why Nixon will let women on the army.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encdr word  0 torch.Size([1, 100]) tensor([[-7.5415e-03, -5.8316e-01, -2.7478e-10, -4.4280e-02, -3.5552e-03,\n",
            "          4.5618e-02,  3.6018e-04, -3.8208e-03,  7.1852e-01, -1.4767e-01,\n",
            "         -8.9210e-11, -6.4771e-07, -4.3824e-02,  7.0296e-01, -7.6156e-01,\n",
            "         -6.4553e-01, -1.0786e-05,  7.1445e-01, -7.7945e-01,  1.3624e-06,\n",
            "          6.9796e-01,  7.6159e-01,  7.6143e-01,  1.8594e-03,  8.1784e-02,\n",
            "         -2.0351e-04, -7.5138e-02, -7.3998e-01,  7.2620e-01, -4.1092e-01,\n",
            "         -7.6149e-01,  1.7712e-02, -1.1448e-01,  3.5338e-01, -7.2695e-01,\n",
            "          2.4874e-01,  7.0965e-01, -3.3222e-03, -7.2947e-01,  4.3954e-04,\n",
            "         -3.7653e-09,  7.5843e-01, -6.7006e-01,  7.1896e-01, -7.8914e-01,\n",
            "          2.6949e-04,  3.4848e-08,  7.4422e-03,  1.5128e-12,  7.6926e-01,\n",
            "         -2.8092e-05,  7.0295e-01, -5.2160e-01, -7.2220e-01, -1.8766e-07,\n",
            "         -6.4822e-01,  7.5101e-01,  8.1824e-10, -6.8574e-01,  2.1851e-01,\n",
            "          3.1777e-04,  3.9399e-05, -9.0248e-23,  1.6040e-09,  6.3198e-01,\n",
            "         -1.7160e-10,  4.4626e-03,  7.4280e-01, -6.8716e-01,  1.0819e-13,\n",
            "          1.1503e-01,  7.5165e-01, -3.3378e-02, -7.5699e-01, -5.2097e-01,\n",
            "         -6.5957e-02,  1.2978e-02, -9.6073e-11, -7.6028e-01, -5.5529e-06,\n",
            "          5.6494e-01, -7.4589e-01, -2.9987e-02,  1.6932e-01, -1.6930e-13,\n",
            "         -1.1324e-06, -2.3541e-04, -7.9287e-01,  7.3163e-01, -1.7580e-03,\n",
            "         -8.3766e-06,  1.7785e-03,  1.6159e-18, -3.4959e-12, -2.5781e-05,\n",
            "          1.5970e-01,  1.2365e-06, -8.0057e-01, -7.4605e-05,  7.6138e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  1 torch.Size([1, 100]) tensor([[ 2.6519e-01, -2.5355e-02, -3.4752e-14, -7.5355e-01, -7.7675e-01,\n",
            "          1.2070e-08,  4.9756e-02, -1.0227e-01,  2.2362e-02, -1.5153e-01,\n",
            "         -6.9826e-16,  7.8736e-02,  8.4858e-20,  1.7382e-03, -4.7701e-03,\n",
            "         -1.0470e-04,  1.0424e-04, -1.6688e-06, -7.2121e-01, -7.1034e-01,\n",
            "          7.9090e-10, -1.7995e-01,  2.3645e-03,  7.3208e-01, -2.3730e-06,\n",
            "         -7.8285e-03,  2.7265e-01, -6.8983e-02,  2.0472e-01, -1.6335e-01,\n",
            "         -1.7991e-01,  6.2031e-01, -9.5944e-01,  2.1096e-05, -5.2736e-05,\n",
            "          2.2048e-08,  1.2749e-05,  1.5458e-01,  2.4052e-02,  4.2995e-04,\n",
            "         -8.1020e-02,  1.1787e-01,  6.4892e-04,  3.4550e-08, -7.3566e-04,\n",
            "          6.9082e-09, -3.3348e-02, -1.0713e-05,  1.4216e-01,  8.8304e-01,\n",
            "         -6.7917e-11,  1.6431e-01,  3.4821e-02, -1.4169e-01,  1.1769e-03,\n",
            "          1.4359e-06,  1.4455e-03, -1.3624e-02, -2.1078e-07, -5.8367e-01,\n",
            "         -1.9295e-02, -7.6891e-08, -3.7933e-12,  6.8046e-06,  1.0999e-07,\n",
            "         -1.1299e-10,  1.3669e-01,  3.4885e-01,  7.5875e-01,  1.2602e-04,\n",
            "          8.0995e-01,  2.2053e-05,  1.0874e-02, -7.1886e-02, -2.1541e-01,\n",
            "         -1.4984e-03, -2.7696e-01, -2.6795e-01, -8.2061e-04, -5.1009e-06,\n",
            "          2.1023e-04, -1.1432e-08,  6.5461e-01,  2.8369e-06, -7.6159e-01,\n",
            "         -3.9291e-04, -8.6538e-17, -2.6525e-05,  3.7573e-07, -4.1646e-10,\n",
            "         -1.1047e-12, -1.6030e-04,  1.1784e-11,  1.7528e-02, -7.0097e-05,\n",
            "          2.8603e-04,  1.2882e-02, -1.0697e-01, -1.5114e-10, -2.4601e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  2 torch.Size([1, 100]) tensor([[ 7.6822e-01, -8.6972e-01, -2.5122e-07, -5.2501e-02, -1.1159e-02,\n",
            "          1.8218e-01,  9.6427e-05, -3.9110e-01,  3.6913e-04, -2.9222e-09,\n",
            "          4.1977e-12,  1.0162e-08, -7.6158e-01, -1.8935e-02, -1.5893e-02,\n",
            "         -6.2593e-03,  2.5309e-03,  3.2572e-01, -7.5770e-01, -1.5420e-08,\n",
            "         -2.9643e-09,  7.6147e-01, -5.6750e-05,  1.9953e-07, -7.6159e-01,\n",
            "         -7.8175e-08, -1.3673e-01, -1.9144e-01,  7.4108e-01, -4.6283e-04,\n",
            "         -2.1844e-02,  1.0613e-08, -2.4194e-12, -6.1795e-01,  2.6023e-01,\n",
            "         -1.5972e-05, -3.4860e-11, -5.4592e-01,  1.9818e-04,  4.3595e-08,\n",
            "         -8.7309e-02, -7.1095e-01, -9.1158e-04,  8.9633e-01, -6.8740e-09,\n",
            "         -5.1744e-09, -1.1033e-01, -7.0318e-01,  7.3771e-10,  9.8611e-01,\n",
            "         -5.1615e-05,  1.6416e-01, -4.1961e-02, -8.6808e-06,  5.9258e-04,\n",
            "         -2.8682e-02, -2.3678e-03, -1.8917e-04, -9.5078e-01, -7.4365e-01,\n",
            "         -7.4212e-01, -3.0196e-03, -9.3731e-14,  7.6100e-01, -6.0896e-14,\n",
            "          6.0125e-01, -4.8697e-01,  1.0756e-10,  9.3040e-02,  7.4877e-04,\n",
            "          7.6793e-01, -1.1652e-03,  3.9493e-02,  5.0683e-04, -9.9329e-08,\n",
            "         -7.2180e-07, -5.8342e-01, -1.6477e-05,  1.8122e-04,  5.6621e-01,\n",
            "          4.1518e-01,  6.0593e-01,  9.4505e-01,  1.3152e-03,  2.5837e-02,\n",
            "         -2.6293e-04, -5.1191e-10, -7.2053e-01,  9.9067e-01, -1.5884e-05,\n",
            "         -3.6059e-08, -7.4520e-02, -1.0889e-09,  2.7856e-06,  7.6151e-01,\n",
            "         -7.5965e-01,  7.6647e-01, -3.2655e-01,  7.2805e-01,  3.5011e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  3 torch.Size([1, 100]) tensor([[ 7.5972e-01,  4.0791e-01,  2.4253e-01, -8.0849e-04,  7.6190e-02,\n",
            "         -4.8953e-02,  7.7752e-01, -6.3404e-15, -7.5842e-01, -3.9010e-04,\n",
            "         -3.5795e-02,  1.2018e-02, -2.3236e-01, -7.6939e-01, -3.8339e-03,\n",
            "          7.6118e-01, -3.8257e-12, -2.4114e-01,  1.8477e-09,  7.4448e-01,\n",
            "          7.6123e-01, -1.7579e-02, -9.6665e-03,  6.1852e-01, -1.0138e-02,\n",
            "          7.6137e-01, -1.1582e-20, -1.7762e-01, -7.5318e-01, -7.6147e-01,\n",
            "         -7.9444e-01,  1.0610e-05, -1.2842e-01, -1.0750e-04,  2.4145e-14,\n",
            "         -2.8269e-04, -2.6701e-01, -1.0075e-14,  9.3421e-01, -7.5947e-01,\n",
            "         -5.8326e-29,  1.2855e-16,  7.6127e-01, -4.9779e-07,  7.6159e-01,\n",
            "          7.5160e-01,  9.6063e-02, -6.7944e-03, -4.0029e-01, -3.0279e-01,\n",
            "          7.6152e-01, -5.5284e-01,  7.5582e-01,  5.0766e-08,  7.6189e-01,\n",
            "         -4.8528e-01, -6.6370e-04, -4.5236e-13, -9.9311e-01, -5.2583e-01,\n",
            "         -6.6325e-07, -9.3823e-01, -7.6159e-01, -7.6140e-01,  3.0575e-02,\n",
            "          4.9652e-08,  2.1458e-01, -3.4403e-04,  8.5933e-11, -3.2688e-02,\n",
            "         -7.6086e-01, -4.7407e-09,  2.6289e-04,  7.2220e-08,  7.0849e-08,\n",
            "          4.9357e-01, -1.4129e-30, -2.2319e-20, -7.6146e-01,  1.7725e-23,\n",
            "         -7.6143e-01,  3.4804e-01, -1.5826e-11,  4.6264e-08,  4.5970e-09,\n",
            "         -2.7142e-03, -1.6586e-20,  8.9221e-02,  1.1707e-05, -7.4598e-01,\n",
            "          7.6122e-01, -8.0012e-01, -1.9655e-05, -7.5505e-01,  9.5108e-06,\n",
            "         -9.6388e-01,  2.2800e-05, -2.6216e-01,  1.9586e-03,  5.2842e-11]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  4 torch.Size([1, 100]) tensor([[ 2.1142e-13, -2.5722e-04, -1.4731e-04, -1.0069e-19,  1.6583e-04,\n",
            "         -7.1509e-01, -7.5608e-01, -2.0712e-30,  7.3529e-03,  7.4564e-01,\n",
            "         -3.5772e-02,  9.0410e-04, -7.3919e-01, -7.6188e-01, -9.6598e-09,\n",
            "         -6.4259e-01, -3.3181e-10,  5.3532e-01, -2.6789e-15,  7.4448e-01,\n",
            "          1.6441e-07,  9.1306e-11,  7.6159e-01,  7.9683e-01, -3.1072e-26,\n",
            "          4.5602e-01,  5.0556e-27, -4.4340e-16,  1.9121e-02, -4.0302e-09,\n",
            "         -6.2978e-02, -1.9319e-03, -8.1072e-01,  8.6892e-18, -8.6371e-20,\n",
            "          7.6148e-01,  9.6242e-06, -4.8733e-19,  5.9831e-01,  4.2611e-04,\n",
            "         -7.6159e-01,  1.3203e-03, -7.7729e-04, -1.7796e-02, -6.2466e-05,\n",
            "         -2.7585e-01,  6.5299e-01, -7.6167e-01,  5.1976e-01,  5.1100e-01,\n",
            "         -3.5675e-01, -1.3974e-09, -1.3606e-02,  5.8088e-05, -2.1966e-01,\n",
            "         -7.5944e-01,  1.8847e-04, -3.9676e-03, -8.6342e-02, -1.1394e-10,\n",
            "          1.1029e-08, -7.7554e-01, -1.8324e-01, -2.7173e-20,  7.9692e-01,\n",
            "         -1.3208e-06,  1.7867e-06, -1.1955e-03,  7.8070e-01,  9.4182e-02,\n",
            "         -1.1727e-16,  7.5094e-01, -3.4765e-02, -7.6134e-01,  2.7368e-01,\n",
            "          4.9077e-01, -1.5347e-04, -7.6156e-01,  7.6159e-01,  4.6606e-19,\n",
            "          1.5772e-01, -8.3986e-03, -2.6814e-24, -7.4416e-01,  6.4894e-12,\n",
            "         -1.7551e-20, -7.3988e-01, -7.4168e-01, -7.5294e-01,  7.6066e-01,\n",
            "          7.6007e-01, -6.3766e-03, -7.6160e-01,  1.5393e-02, -7.1044e-01,\n",
            "         -7.6073e-01,  4.6679e-10,  6.0780e-01, -2.8383e-01, -1.0851e-08]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  5 torch.Size([1, 100]) tensor([[ 1.3616e-06,  7.2829e-01,  4.8979e-02,  1.4825e-01,  7.6163e-01,\n",
            "         -1.5157e-03, -1.7783e-01, -1.1390e-05, -7.5633e-01,  6.6553e-08,\n",
            "         -1.1103e-05, -7.5557e-01, -1.9379e-16, -2.3255e-01,  6.6882e-02,\n",
            "         -7.5788e-01,  6.4748e-01, -2.5137e-01,  8.7192e-08, -2.3361e-02,\n",
            "         -1.0990e-11, -7.2312e-01,  3.4722e-11, -5.2029e-01, -9.4193e-06,\n",
            "          9.0367e-01, -1.9652e-01,  6.8982e-01,  5.9623e-03, -1.7523e-05,\n",
            "         -1.4594e-16, -1.3737e-04,  8.4434e-11,  3.6757e-11,  3.5395e-01,\n",
            "          2.3450e-23, -2.0102e-06,  5.2956e-01,  2.7888e-08, -7.6149e-01,\n",
            "         -7.6159e-01, -8.5843e-04,  8.2960e-02, -7.6159e-01,  5.0123e-12,\n",
            "          7.5911e-01,  6.5595e-01,  1.4011e-03, -5.9050e-01, -7.6158e-01,\n",
            "          7.4939e-01, -7.4399e-01,  2.0558e-02, -1.6311e-08,  1.7329e-05,\n",
            "         -3.7177e-01, -2.8697e-03,  6.5881e-04,  7.0524e-01,  2.2739e-01,\n",
            "         -7.6119e-01,  6.8544e-01, -5.5849e-09, -7.6159e-01,  1.0997e-06,\n",
            "         -7.5616e-03,  2.8806e-02, -1.8971e-20,  1.9295e-03, -5.6067e-01,\n",
            "          2.4711e-07, -4.4565e-05,  5.6602e-03,  3.5933e-07,  7.3774e-01,\n",
            "          3.8771e-03, -2.7764e-04, -1.2614e-07, -2.1813e-17,  7.5386e-01,\n",
            "         -9.0140e-02, -7.5521e-01, -4.6065e-01, -3.7255e-01, -4.2915e-02,\n",
            "         -7.3590e-01, -3.1395e-04, -3.1079e-07,  1.5238e-02, -8.8181e-06,\n",
            "          7.8294e-01, -8.0057e-01, -2.1427e-02, -7.5505e-01,  7.0540e-01,\n",
            "         -1.4602e-01,  7.6166e-01, -6.8630e-11, -1.6731e-02,  7.6159e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  6 torch.Size([1, 100]) tensor([[ 2.7391e-04,  7.8007e-01,  8.0085e-01,  6.3341e-05,  7.6821e-01,\n",
            "         -7.0081e-04,  6.5498e-01,  7.6158e-01, -7.4081e-01, -1.9387e-06,\n",
            "         -7.5860e-01,  2.1921e-08,  5.1115e-17, -3.0533e-04,  3.5725e-04,\n",
            "         -1.9586e-06,  7.6359e-01, -7.8620e-01,  8.9216e-01,  7.4393e-01,\n",
            "         -7.6129e-01, -3.7942e-03, -1.6114e-03, -3.0175e-06, -7.4493e-01,\n",
            "          9.0397e-01, -8.3268e-01,  7.3990e-01,  6.8844e-05,  1.7255e-01,\n",
            "          1.9743e-10, -3.2164e-06,  1.8803e-04,  2.1059e-08,  6.0559e-06,\n",
            "         -1.4896e-14, -2.7787e-03,  9.1995e-01,  7.6159e-01, -6.9411e-04,\n",
            "          1.7129e-01, -1.0234e-01,  3.4720e-03, -3.7808e-04,  8.0892e-13,\n",
            "          1.2998e-03,  1.5247e-06,  1.0599e-21, -7.9771e-01, -8.7785e-01,\n",
            "          7.6486e-01, -8.5217e-01,  2.7221e-01,  2.0821e-01,  1.5444e-03,\n",
            "         -2.5556e-03,  2.9576e-01, -5.2251e-01,  5.7776e-08,  2.5155e-05,\n",
            "         -3.3397e-01, -4.4996e-06, -6.4288e-01, -1.1108e-06,  1.1624e-03,\n",
            "          6.2651e-04,  1.5564e-04,  2.8751e-07, -4.0809e-06, -7.9096e-01,\n",
            "         -7.6047e-01, -4.1506e-08,  1.0409e-04,  4.1854e-02,  9.5191e-01,\n",
            "          3.1131e-03, -7.2678e-05,  4.8955e-01, -4.0901e-18,  6.3412e-02,\n",
            "         -5.8060e-11, -8.5878e-04, -9.0484e-01,  2.6753e-01, -1.1599e-04,\n",
            "         -9.6258e-01, -1.1921e-07,  1.5854e-05,  9.1732e-04, -9.7057e-05,\n",
            "          1.1724e-03, -2.8622e-10,  5.3581e-01, -5.6340e-01,  1.2117e-04,\n",
            "         -2.3862e-08,  8.4681e-08, -8.3518e-08, -6.9634e-01,  2.9881e-04]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  7 torch.Size([1, 100]) tensor([[ 1.0153e-02,  9.5483e-12,  8.1215e-05,  1.3825e-07,  5.7590e-01,\n",
            "         -1.5440e-12,  9.4611e-01,  2.2698e-03, -7.3679e-01, -9.2510e-01,\n",
            "         -9.5791e-01,  3.5093e-04,  2.2408e-10, -2.7253e-05,  2.8779e-11,\n",
            "          2.5316e-09,  9.9220e-01, -5.3800e-18,  1.4052e-08,  9.6401e-01,\n",
            "         -6.4166e-01, -3.0878e-02, -2.0104e-01, -7.8342e-01, -1.0450e-13,\n",
            "          9.0113e-01, -8.3015e-01,  5.1938e-03, -7.6138e-01,  3.4565e-11,\n",
            "          5.0547e-01, -7.6186e-01,  6.2805e-01, -7.6049e-01,  1.2513e-16,\n",
            "         -3.1643e-11, -9.6263e-01,  9.8751e-01,  1.1510e-07, -9.9477e-01,\n",
            "          7.6036e-01, -4.3522e-09,  4.8556e-05, -1.4454e-13,  4.2590e-15,\n",
            "          9.8807e-01,  7.6984e-01,  1.0889e-16, -9.6975e-01, -9.7484e-01,\n",
            "          1.0938e-08, -7.5390e-01,  8.5638e-01,  1.8568e-03,  1.3277e-01,\n",
            "          5.0795e-02, -3.1492e-13, -6.8717e-05,  9.6669e-20,  1.4656e-04,\n",
            "         -1.2804e-01, -1.6444e-03, -9.4281e-01, -5.8655e-01, -2.8678e-08,\n",
            "          2.3341e-11, -3.4603e-10,  2.0917e-06,  7.6159e-01, -7.9433e-01,\n",
            "         -7.8105e-01, -8.1869e-04,  7.1078e-01,  9.4680e-01,  1.2870e-11,\n",
            "          7.6225e-01, -5.6686e-02, -1.2235e-01,  1.5402e-14, -1.9819e-15,\n",
            "         -2.7412e-01, -5.4539e-01, -1.0197e-01,  1.0349e-01, -6.3216e-06,\n",
            "         -7.2400e-03, -6.1051e-21,  7.6124e-01,  5.3337e-13, -1.0448e-10,\n",
            "          8.7888e-01, -7.6155e-01, -6.9571e-10, -5.5903e-01,  2.4071e-04,\n",
            "         -4.2417e-01,  3.4114e-07,  3.1702e-04,  2.4494e-04,  1.7196e-09]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  8 torch.Size([1, 100]) tensor([[ 8.1256e-01,  0.0000e+00,  7.6160e-01,  2.2086e-26,  7.6160e-01,\n",
            "         -9.2937e-01,  9.9254e-01,  9.4829e-02, -9.6078e-01, -9.8952e-01,\n",
            "         -3.7724e-01,  2.9617e-17,  0.0000e+00, -5.0080e-29,  3.2715e-01,\n",
            "          3.5032e-44,  9.9894e-01, -0.0000e+00,  0.0000e+00,  9.9505e-01,\n",
            "         -9.9411e-01, -1.8920e-18, -9.6410e-01, -7.8342e-01, -2.3580e-37,\n",
            "          2.3646e-03, -5.2484e-13,  7.6157e-01, -9.6402e-01,  2.5269e-37,\n",
            "          2.2013e-02, -9.6407e-01,  9.5314e-01, -9.6403e-01,  0.0000e+00,\n",
            "         -6.4034e-12, -9.9486e-01,  1.4510e-02,  9.6932e-01, -9.9929e-01,\n",
            "          7.5759e-01, -0.0000e+00,  0.0000e+00, -0.0000e+00,  1.1053e-38,\n",
            "          9.9887e-01,  9.6541e-01,  8.6698e-34, -9.9585e-01, -9.9761e-01,\n",
            "          0.0000e+00, -4.0600e-06,  9.7928e-01,  5.2833e-31,  9.6448e-01,\n",
            "          7.8213e-01, -0.0000e+00, -4.2039e-45,  0.0000e+00,  0.0000e+00,\n",
            "         -2.3761e-08, -6.7550e-41, -9.9206e-01, -9.6403e-01, -7.9560e-34,\n",
            "          1.6317e-20, -0.0000e+00, -1.1701e-03,  7.6159e-01, -9.6945e-01,\n",
            "         -9.6730e-01, -6.1891e-06,  2.2750e-32,  9.9467e-01,  5.1996e-11,\n",
            "          9.6414e-01, -5.0262e-04, -7.6159e-01,  3.0075e-28, -8.4438e-37,\n",
            "         -1.2324e-15,  3.6898e-01, -4.0238e-02,  1.4330e-06, -1.1989e-29,\n",
            "         -9.5316e-01,  5.2127e-39,  3.2764e-02, -1.0905e-10, -2.8026e-45,\n",
            "          9.8266e-01, -7.6159e-01, -1.2885e-02, -9.2742e-01,  9.5014e-01,\n",
            "         -9.4313e-04,  6.1706e-29,  3.6005e-02,  8.6426e-01,  0.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  9 torch.Size([1, 100]) tensor([[ 9.7240e-01,  5.0242e-04,  9.6394e-01,  9.0024e-15,  1.7675e-09,\n",
            "         -9.8811e-01,  4.9386e-05,  8.5482e-10, -9.9420e-01, -9.9857e-01,\n",
            "         -5.3844e-01,  1.3236e-23,  7.5939e-01, -7.6176e-01,  3.7534e-04,\n",
            "          7.3320e-02,  9.9986e-01, -2.5892e-30,  2.9146e-07,  9.9384e-01,\n",
            "         -9.5413e-01, -6.0927e-15, -9.9501e-01, -7.6192e-01, -4.0823e-30,\n",
            "          1.2462e-08, -7.6159e-01,  9.6351e-01, -9.9504e-01,  4.2858e-12,\n",
            "          9.6211e-01, -9.7474e-01,  9.7671e-01, -9.6102e-01,  6.9500e-16,\n",
            "         -9.5600e-01, -9.9930e-01,  1.0472e-02,  1.7024e-02, -9.9990e-01,\n",
            "          1.5100e-07, -1.1175e-08,  4.5298e-13, -4.6576e-26,  1.4008e-07,\n",
            "          5.3666e-04,  9.9525e-01,  7.3554e-01, -9.9943e-01, -5.6881e-07,\n",
            "          1.3477e-08, -2.1778e-10,  9.9716e-01,  7.6157e-01,  9.9512e-01,\n",
            "          9.6745e-01, -4.3862e-15, -1.0433e-04,  7.3050e-15,  8.2974e-03,\n",
            "         -5.3145e-07, -3.1615e-04, -9.9892e-01, -9.9501e-01, -1.5923e-08,\n",
            "          1.3474e-16, -7.5148e-01, -9.7600e-17,  9.6376e-01, -9.5208e-02,\n",
            "         -8.7310e-01, -7.6212e-01,  1.1214e-10,  9.9927e-01,  7.6159e-01,\n",
            "          9.8219e-01, -1.2297e-12, -9.5754e-01, -6.3560e-01, -2.7903e-21,\n",
            "         -7.6160e-01,  3.8023e-01, -1.4356e-09,  7.6947e-16, -6.9399e-05,\n",
            "         -3.3537e-10,  7.3901e-01,  8.7644e-01, -3.8725e-11,  2.7262e-01,\n",
            "          7.5686e-01, -6.8164e-06, -3.0624e-07, -8.7604e-01,  9.8380e-01,\n",
            "         -7.6188e-01, -1.3255e-25,  9.6535e-01,  3.4485e-10,  1.7935e-11]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  10 torch.Size([1, 100]) tensor([[ 8.0742e-01,  2.5918e-14,  3.2187e-02,  9.2011e-25,  1.4000e-09,\n",
            "         -7.0363e-04,  9.4638e-01,  1.4013e-45, -9.5819e-01, -9.9815e-01,\n",
            "         -3.6881e-02, -4.5622e-05, -4.8773e-04, -2.2130e-10, -3.2352e-03,\n",
            "          1.9824e-05, -1.0112e-02,  3.7831e-11, -5.2332e-31,  9.6859e-01,\n",
            "         -7.2213e-01,  1.0486e-30, -9.6410e-01, -2.0089e-02,  3.0707e-32,\n",
            "         -7.6044e-01, -1.7485e-10,  3.7696e-05, -9.6396e-01, -2.6496e-07,\n",
            "          1.5975e-01, -9.6250e-01,  8.3982e-01, -2.7081e-01, -3.5380e-16,\n",
            "         -7.1493e-01, -9.9673e-01, -2.7244e-26,  8.8999e-01, -9.9929e-01,\n",
            "         -1.9204e-18,  9.8701e-23,  1.9923e-07,  8.2552e-14,  5.8260e-01,\n",
            "          9.9998e-01,  9.9936e-01, -7.4303e-01, -9.9992e-01,  4.2034e-07,\n",
            "          2.7712e-13,  2.5593e-26,  9.7924e-01, -8.3058e-04,  9.6448e-01,\n",
            "          9.9524e-01, -7.7938e-13, -7.6133e-01,  4.8957e-08,  8.0816e-14,\n",
            "          8.3687e-32, -4.4304e-21,  3.4223e-08,  6.9346e-01,  8.4760e-02,\n",
            "         -5.2188e-34, -3.5214e-06, -8.6224e-17,  9.9502e-01, -1.9367e-09,\n",
            "         -1.3528e-03, -1.8888e-08,  1.1013e-12,  9.9464e-01,  7.5914e-01,\n",
            "          9.5713e-01, -2.9843e-20, -7.5502e-01,  2.4704e-01,  1.2364e-39,\n",
            "         -5.5254e-05, -5.7445e-01, -2.1067e-35, -3.7233e-17,  5.7527e-01,\n",
            "         -3.7869e-26,  7.0881e-17,  6.1220e-01,  1.0526e-02,  9.6403e-01,\n",
            "          6.9320e-05, -7.3245e-01, -7.6610e-01, -4.9068e-01,  9.4262e-01,\n",
            "         -6.8307e-04, -2.9401e-12,  9.9524e-01, -1.8357e-43, -3.1241e-16]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  11 torch.Size([1, 100]) tensor([[ 9.7156e-01, -1.2746e-39,  9.6160e-01, -1.6906e-35,  3.0338e-18,\n",
            "         -3.4040e-13,  9.9057e-01,  1.2738e-24, -9.8413e-01, -9.8647e-01,\n",
            "         -2.5912e-03, -4.1298e-05,  7.4280e-01,  6.9627e-14, -3.0295e-19,\n",
            "          8.6802e-25, -9.5602e-01, -1.0591e-17,  4.3440e-44,  9.9569e-01,\n",
            "          8.7697e-02, -1.7047e-32, -9.9506e-01, -7.6990e-01,  7.2868e-44,\n",
            "         -4.6778e-03, -6.1429e-22,  4.1632e-11, -9.9504e-01,  2.4925e-15,\n",
            "          8.2141e-01, -9.9484e-01,  9.7671e-01, -5.4270e-01,  3.6293e-33,\n",
            "          6.1802e-02, -9.9956e-01,  3.8132e-30,  9.8437e-01, -9.9990e-01,\n",
            "          5.9197e-07, -0.0000e+00,  3.2044e-10, -1.4989e-31,  9.3075e-01,\n",
            "          1.0000e+00,  9.9991e-01,  7.5997e-01, -9.9999e-01,  1.9740e-14,\n",
            "          1.4889e-23, -1.0415e-35,  9.9716e-01,  1.5088e-15,  7.7043e-01,\n",
            "          9.9935e-01,  4.6589e-37, -4.8575e-01,  9.6795e-29,  6.7727e-20,\n",
            "          7.0065e-43, -1.9437e-19, -5.4308e-02, -1.3460e-01,  7.5697e-03,\n",
            "          3.8588e-31, -1.5657e-26, -7.6159e-01,  9.9932e-01, -3.8789e-01,\n",
            "         -2.8927e-10,  4.2618e-01,  1.2450e-22,  9.8924e-01,  4.4834e-05,\n",
            "          9.9409e-01, -1.2695e-22, -9.6398e-01, -5.5687e-01, -1.7375e-30,\n",
            "         -7.5511e-01, -5.7439e-01,  2.8301e-41,  1.3165e-12, -5.2538e-06,\n",
            "         -0.0000e+00,  8.1697e-17,  9.3608e-01, -6.2562e-03,  8.5229e-02,\n",
            "         -6.0115e-02, -9.5879e-01, -7.1946e-01, -9.1161e-01,  9.9113e-01,\n",
            "          7.6131e-01,  9.9334e-25,  9.9935e-01,  4.8354e-30, -7.4838e-38]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  12 torch.Size([1, 100]) tensor([[ 8.6283e-01,  4.3449e-14,  7.6159e-01,  3.0115e-33,  5.9379e-25,\n",
            "         -1.7221e-07,  9.9872e-01,  9.3408e-38, -9.9784e-01, -9.0553e-01,\n",
            "          5.5460e-03, -4.2403e-24,  9.6402e-01,  1.6017e-08,  4.1291e-06,\n",
            "          9.6289e-05, -9.8389e-01, -2.8404e-04,  7.6321e-21,  9.9222e-01,\n",
            "         -7.2213e-01, -3.3146e-20, -9.9669e-01, -7.9003e-01, -6.1793e-19,\n",
            "          6.9477e-01, -1.7885e-19,  3.7333e-01, -9.6395e-01, -6.3733e-05,\n",
            "          8.9800e-01, -9.9930e-01,  9.9682e-01, -7.3341e-01,  7.3389e-13,\n",
            "         -7.6155e-01, -9.9994e-01,  5.4263e-17,  9.9787e-01, -9.9949e-01,\n",
            "          8.5307e-25,  2.6290e-19,  5.9205e-13, -0.0000e+00,  9.0063e-01,\n",
            "          9.9998e-01,  2.2983e-03,  2.1615e-01, -1.0000e+00,  5.9114e-28,\n",
            "          7.1636e-03, -2.3880e-20,  9.9962e-01,  7.6159e-01,  9.6542e-01,\n",
            "          9.9991e-01, -3.3557e-03, -7.6159e-01,  7.6153e-01,  1.8906e-16,\n",
            "         -1.4771e-28, -3.7772e-01, -7.6159e-01, -8.1054e-01, -7.6159e-01,\n",
            "          7.2987e-19, -5.6374e-05, -4.7430e-01,  9.9990e-01, -7.6253e-01,\n",
            "         -5.3684e-20, -4.7870e-01,  1.9328e-30,  9.9854e-01,  9.5005e-01,\n",
            "          9.9920e-01, -2.8050e-21, -2.9239e-01, -9.2582e-01, -6.3878e-18,\n",
            "         -9.6293e-01,  3.3278e-01, -4.0987e-31,  7.2999e-01, -1.0025e-38,\n",
            "         -3.9360e-27,  1.5968e-23,  9.9110e-01, -3.9364e-15,  9.9921e-01,\n",
            "          7.1231e-14, -3.4933e-01,  9.0011e-02, -9.8756e-01,  9.9878e-01,\n",
            "          9.6398e-01, -1.7063e-02,  9.9991e-01,  3.1621e-10,  7.8305e-10]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  0 torch.Size([1, 100]) tensor([[-7.4494e-01,  8.0216e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          8.0473e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -8.1030e-01,  0.0000e+00,  4.7953e-17,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, -7.6562e-01,  0.0000e+00,\n",
            "          0.0000e+00,  2.6597e-26,  7.7327e-01,  0.0000e+00,  0.0000e+00,\n",
            "          7.5182e-01,  8.4748e-01,  7.6820e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -8.1400e-01, -5.7905e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -8.1752e-01, -0.0000e+00, -7.2009e-01, -7.2648e-01,  0.0000e+00,\n",
            "          6.7132e-01, -3.8346e-02,  0.0000e+00,  0.0000e+00, -8.0219e-01,\n",
            "          0.0000e+00,  8.3209e-01,  7.7778e-01, -4.4587e-19,  7.4119e-01,\n",
            "         -7.3814e-01,  0.0000e+00,  6.8164e-01, -0.0000e+00,  0.0000e+00,\n",
            "         -7.3175e-01,  0.0000e+00,  0.0000e+00,  8.5904e-01, -0.0000e+00,\n",
            "         -7.7331e-01, -1.0280e-34,  0.0000e+00, -7.0357e-01,  0.0000e+00,\n",
            "         -7.8240e-01,  8.3582e-01,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -7.3993e-01, -2.8529e-01, -0.0000e+00, -0.0000e+00,  7.6179e-01,\n",
            "         -7.9266e-01, -2.1063e-22,  0.0000e+00, -7.6172e-01,  8.1259e-01,\n",
            "          8.1563e-01,  0.0000e+00,  0.0000e+00,  8.0328e-01, -0.0000e+00,\n",
            "         -2.0165e-42,  0.0000e+00,  7.8407e-01,  7.6031e-01,  0.0000e+00,\n",
            "          7.7976e-01, -0.0000e+00,  7.0464e-01, -0.0000e+00, -1.3655e-39,\n",
            "         -7.5187e-01,  6.8977e-01,  7.0765e-01,  0.0000e+00,  6.5801e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  1 torch.Size([1, 100]) tensor([[-9.6120e-01,  9.7072e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.7114e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.7203e-01,  0.0000e+00,  1.4135e-32,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.6470e-01,  0.0000e+00,\n",
            "          0.0000e+00,  3.0006e-38,  9.6598e-01,  0.0000e+00,  0.0000e+00,\n",
            "          9.6238e-01,  9.7790e-01,  9.6514e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -9.7263e-01, -9.3036e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.7319e-01, -0.0000e+00, -9.5690e-01, -9.5802e-01,  0.0000e+00,\n",
            "          9.4815e-01, -3.8346e-02,  0.0000e+00,  0.0000e+00, -9.7111e-01,\n",
            "          0.0000e+00,  9.7550e-01,  9.6673e-01,  1.1981e-42,  9.6056e-01,\n",
            "         -9.6004e-01,  0.0000e+00,  9.5004e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.5893e-01,  0.0000e+00,  0.0000e+00,  9.7968e-01, -0.0000e+00,\n",
            "         -9.6599e-01,  0.0000e+00,  0.0000e+00, -9.5399e-01,  0.0000e+00,\n",
            "         -9.6749e-01,  9.7608e-01,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -9.6035e-01, -1.4697e-08, -0.0000e+00, -0.0000e+00,  9.6406e-01,\n",
            "         -9.6917e-01, -4.7761e-24,  0.0000e+00, -9.6405e-01,  9.7240e-01,\n",
            "          9.7289e-01,  0.0000e+00,  0.0000e+00,  9.7090e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.6777e-01,  9.6381e-01,  0.0000e+00,\n",
            "          9.6706e-01, -0.0000e+00,  9.5418e-01, -0.0000e+00, -0.0000e+00,\n",
            "         -9.6238e-01,  9.5151e-01,  9.5471e-01,  0.0000e+00,  9.4569e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  2 torch.Size([1, 100]) tensor([[-9.9466e-01,  9.9599e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9604e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9617e-01,  0.0000e+00,  8.1557e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9515e-01,  0.0000e+00,\n",
            "          0.0000e+00,  1.3870e-41,  9.9533e-01,  0.0000e+00,  0.0000e+00,\n",
            "          9.9482e-01,  9.9698e-01,  9.9521e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -9.9625e-01, -9.9028e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9633e-01, -0.0000e+00, -9.9406e-01, -9.9421e-01,  0.0000e+00,\n",
            "          9.9282e-01, -3.8346e-02,  0.0000e+00,  0.0000e+00, -9.9604e-01,\n",
            "          0.0000e+00,  9.9665e-01,  9.9543e-01,  0.0000e+00,  9.9457e-01,\n",
            "         -9.9450e-01,  0.0000e+00,  9.9309e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9434e-01,  0.0000e+00,  0.0000e+00,  9.9723e-01, -0.0000e+00,\n",
            "         -9.9533e-01,  0.0000e+00,  0.0000e+00, -9.9365e-01,  0.0000e+00,\n",
            "         -9.9554e-01,  9.9673e-01,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9454e-01, -2.9999e-11, -0.0000e+00, -0.0000e+00,  9.9506e-01,\n",
            "         -9.9577e-01, -2.1472e-24,  0.0000e+00, -9.9506e-01,  9.9622e-01,\n",
            "          9.9629e-01,  0.0000e+00,  0.0000e+00,  9.9601e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9558e-01,  9.9502e-01,  0.0000e+00,\n",
            "          9.9548e-01, -0.0000e+00,  9.9367e-01, -0.0000e+00, -0.0000e+00,\n",
            "         -9.9483e-01,  9.9330e-01,  9.9375e-01,  0.0000e+00,  9.9247e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  3 torch.Size([1, 100]) tensor([[-9.9928e-01,  9.9946e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9946e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9948e-01,  0.0000e+00,  1.6138e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9934e-01,  0.0000e+00,\n",
            "          0.0000e+00,  3.7709e-42,  9.9937e-01,  0.0000e+00,  0.0000e+00,\n",
            "          9.9930e-01,  9.9959e-01,  9.9935e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -9.9949e-01, -9.9868e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9950e-01, -0.0000e+00, -9.9919e-01, -9.9921e-01,  0.0000e+00,\n",
            "          9.9903e-01, -3.8346e-02,  0.0000e+00,  0.0000e+00, -9.9946e-01,\n",
            "          0.0000e+00,  9.9955e-01,  9.9938e-01,  0.0000e+00,  9.9926e-01,\n",
            "         -9.9925e-01,  0.0000e+00,  9.9906e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9923e-01,  0.0000e+00,  0.0000e+00,  9.9962e-01, -0.0000e+00,\n",
            "         -9.9937e-01,  0.0000e+00,  0.0000e+00, -9.9914e-01,  0.0000e+00,\n",
            "         -9.9939e-01,  9.9956e-01,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9926e-01, -2.6228e-12, -0.0000e+00, -0.0000e+00,  9.9933e-01,\n",
            "         -9.9943e-01, -1.8074e-24,  0.0000e+00, -9.9933e-01,  9.9949e-01,\n",
            "          9.9950e-01,  0.0000e+00,  0.0000e+00,  9.9946e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9940e-01,  9.9933e-01,  0.0000e+00,\n",
            "          9.9939e-01, -0.0000e+00,  9.9914e-01, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9930e-01,  9.9909e-01,  9.9915e-01,  0.0000e+00,  9.9898e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  4 torch.Size([1, 100]) tensor([[-9.9990e-01,  9.9993e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9993e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9993e-01,  0.0000e+00,  1.2904e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9991e-01,  0.0000e+00,\n",
            "          0.0000e+00,  3.1501e-42,  9.9991e-01,  0.0000e+00,  0.0000e+00,\n",
            "          9.9990e-01,  9.9994e-01,  9.9991e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -9.9993e-01, -9.9982e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9993e-01, -0.0000e+00, -9.9989e-01, -9.9989e-01,  0.0000e+00,\n",
            "          9.9987e-01, -3.8346e-02,  0.0000e+00,  0.0000e+00, -9.9993e-01,\n",
            "          0.0000e+00,  9.9994e-01,  9.9992e-01,  0.0000e+00,  9.9990e-01,\n",
            "         -9.9990e-01,  0.0000e+00,  9.9987e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9990e-01,  0.0000e+00,  0.0000e+00,  9.9995e-01, -0.0000e+00,\n",
            "         -9.9991e-01,  0.0000e+00,  0.0000e+00, -9.9988e-01,  0.0000e+00,\n",
            "         -9.9992e-01,  9.9994e-01,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9990e-01, -4.3551e-13, -0.0000e+00, -0.0000e+00,  9.9991e-01,\n",
            "         -9.9992e-01, -1.7650e-24,  0.0000e+00, -9.9991e-01,  9.9993e-01,\n",
            "          9.9993e-01,  0.0000e+00,  0.0000e+00,  9.9993e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9992e-01,  9.9991e-01,  0.0000e+00,\n",
            "          9.9992e-01, -0.0000e+00,  9.9988e-01, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9990e-01,  9.9988e-01,  9.9989e-01,  0.0000e+00,  9.9986e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  5 torch.Size([1, 100]) tensor([[-9.9999e-01,  9.9999e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9999e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9999e-01,  0.0000e+00,  1.2518e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9999e-01,  0.0000e+00,\n",
            "          0.0000e+00,  3.0744e-42,  9.9999e-01,  0.0000e+00,  0.0000e+00,\n",
            "          9.9999e-01,  9.9999e-01,  9.9999e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -9.9999e-01, -9.9998e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9999e-01, -0.0000e+00, -9.9999e-01, -9.9999e-01,  0.0000e+00,\n",
            "          9.9998e-01, -3.8346e-02,  0.0000e+00,  0.0000e+00, -9.9999e-01,\n",
            "          0.0000e+00,  9.9999e-01,  9.9999e-01,  0.0000e+00,  9.9999e-01,\n",
            "         -9.9999e-01,  0.0000e+00,  9.9998e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9999e-01,  0.0000e+00,  0.0000e+00,  9.9999e-01, -0.0000e+00,\n",
            "         -9.9999e-01,  0.0000e+00,  0.0000e+00, -9.9998e-01,  0.0000e+00,\n",
            "         -9.9999e-01,  9.9999e-01,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9999e-01, -7.9032e-14, -0.0000e+00, -0.0000e+00,  9.9999e-01,\n",
            "         -9.9999e-01, -1.7594e-24,  0.0000e+00, -9.9999e-01,  9.9999e-01,\n",
            "          9.9999e-01,  0.0000e+00,  0.0000e+00,  9.9999e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9999e-01,  9.9999e-01,  0.0000e+00,\n",
            "          9.9999e-01, -0.0000e+00,  9.9998e-01, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9999e-01,  9.9998e-01,  9.9998e-01,  0.0000e+00,  9.9998e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  6 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.2467e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  3.0632e-42,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -3.8346e-02,  0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00, -1.4516e-14, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -1.7586e-24,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  7 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.2460e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  3.0618e-42,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -3.8346e-02,  0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00, -2.6706e-15, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -1.7585e-24,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  8 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.2459e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  3.0618e-42,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -3.8346e-02,  0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00, -4.9147e-16, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -1.7585e-24,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  9 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.2459e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  3.0618e-42,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -3.8346e-02,  0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00, -9.0476e-17, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -1.7585e-24,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  10 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.2459e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  3.0618e-42,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -3.8346e-02,  0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00, -1.6685e-17, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -1.7585e-24,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  11 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.2459e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  3.0618e-42,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -3.8346e-02,  0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00, -3.1064e-18, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -1.7585e-24,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  12 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.2459e-37,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  3.0618e-42,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -3.8346e-02,  0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00, -6.0754e-19, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -1.7585e-24,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HwjrPw0W-qu"
      },
      "source": [
        "## Testing the model on 10 random review comments from the validation set to predict the label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBCajTM636dI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0ffa605-d6a9-404e-cf3d-42a7fb26b667"
      },
      "source": [
        "import random \n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "TESTSAMPLE = 10\n",
        "\n",
        "validindex = np.arange (len(valid))\n",
        "\n",
        "printEncoderDecoderOutput = False\n",
        "randindex = random.choices(validindex , k=10)\n",
        "\n",
        "sentenceLabelPrediction = []\n",
        "\n",
        "for i in range(TESTSAMPLE)  :\n",
        "  slp = {}\n",
        "  out = vars(valid.examples[randindex[i]])\n",
        "  \n",
        "  true_label = categories[out['label']]\n",
        "  in_tweet = ' '.join(out['tweet'])\n",
        "  pred_label = classify_tweet(in_tweet)\n",
        "\n",
        "  strTruelabel = 'True label: ' + str(true_label)\n",
        "  strPredlabel = 'Predicted label: ' +  str(pred_label)\n",
        "  strSentence =  'Input Sentence: ' + in_tweet\n",
        "  slp['Truelabel'] = true_label\n",
        "  slp['Predictedlabel'] = pred_label\n",
        "  slp['Input Sentence'] = in_tweet\n",
        "\n",
        "  sentenceLabelPrediction.append(slp)\n",
        "  \n",
        "  lineSeparator = '---------------------------------'\n",
        "  display(Markdown('<strong>{}</strong><br><br><strong>{}</strong><br><br>{}<br><br><strong>{}</strong><br><br>'.format(strTruelabel , strPredlabel , strSentence , lineSeparator)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: BUM ! Obama \" threatens \" supreme court justices considering repealing his unconstitutional healthcare law . Nice move bum !<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: @ericbolling # Hillary 's gon na challenge # Obama<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: RT @ohgirlphrase : American kid \" You 're from the UK ? Ohhh cool , So do you have tea with the Queen ? \" . British kid : \" Do you like , go to Mcdonalds with Obama ?<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: @AC360   President Obama is a Constitutional Law scholar - give him credit and the respect that he deserves .   @JaySekulow is annoying .<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Positive</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: Obama signs JOBS Act to boost startup firms - http://t.co/TFuPTCwT<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: RT @ohgirlphrase : American kid \" You 're from the UK ? Ohhh cool , So do you have tea with the Queen ? \" . British kid : \" Do you like , go to Mcdonalds with Obama ?<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: It 's incredible that something like # WhatsRomneyHiding would be trending . Yet Obama is sneakiest , harmful person and no one says anything .<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: A \" legislator \" who 'd never passed legislation . A \" law professor \" who 'd never published a law review article ... Is Obama fictional ? # hhrs<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: RT @anna12061 : Another Obama Buddy !<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Positive</strong><br><br>Input Sentence: @obama start tweeting dang<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NpzwfiJu0H9"
      },
      "source": [
        "### store the information for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyueHFvP4Yoi"
      },
      "source": [
        "diagnosticDict = {}\n",
        "\n",
        "diagnosticDict['num_hidden_nodes'] = num_hidden_nodes\n",
        "diagnosticDict['epochs'] = N_EPOCHS\n",
        "diagnosticDict['lr'] = learning_rate\n",
        "diagnosticDict['batchsize'] = batch_size\n",
        "diagnosticDict['trainLossList'] = trainLossList\n",
        "diagnosticDict['valLossList']= valLossList\n",
        "diagnosticDict['trainAccyList'] = trainAccyList\n",
        "diagnosticDict['valAccyList'] = valAccyList\n",
        "diagnosticDict['sentencelabelpredict'] = sentenceLabelPrediction\n",
        "\n",
        "#diagnosticDict"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBpGdtqf4iFA"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"encdr_dcdr_lstmdiagnostic.json\", \"a\") as out_file:\n",
        "  json.dump(diagnosticDict, out_file, indent = 6)\n"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}